# **Réponses - Pratique 1 : Choix de l'approche (supervisé, non supervisé ou RL)**  

## **Cas 1 : Détection de fraudes bancaires**  

- **Votre choix :** Apprentissage supervisé  
- **Justification :**  
  - La banque possède **un historique de transactions étiquetées** (fraude ou non-fraude).  
  - Un modèle supervisé peut apprendre à reconnaître **les caractéristiques des fraudes passées** et généraliser à de nouvelles transactions.  
  - Un **algorithme de classification** comme une forêt aléatoire ou un réseau de neurones peut être entraîné sur ces données pour identifier les fraudes futures.  

---

## **Cas 2 : Regroupement clients – grande distribution**  

- **Votre choix :** Apprentissage non supervisé  
- **Justification :**  
  - Aucune **étiquette préexistante** pour classer les clients.  
  - Objectif : **Découvrir des groupes similaires** selon leur comportement d’achat.  
  - Les méthodes de **clustering** (ex. K-Means, DBSCAN) sont adaptées pour identifier **des segments de clientèle** à des fins de marketing ciblé.  

---

## **Cas 3 : Navigation autonome d’un robot industriel**  

- **Votre choix :** Apprentissage par renforcement (RL)  
- **Justification :**  
  - Le robot doit **prendre des décisions séquentielles** pour naviguer.  
  - Il apprend **par essais et erreurs**, en recevant des **récompenses** pour un bon déplacement et des **pénalités** pour un obstacle.  
  - Le RL est **idéal** pour les tâches où **chaque action influence l’état futur**.  
  - Les algorithmes comme **Q-Learning** ou **Deep Q-Networks (DQN)** sont utilisés dans ce type de problème.  

---

## **Cas 4 : Reconnaissance faciale dans une entreprise**  

- **Votre choix :** Apprentissage supervisé  
- **Justification :**  
  - Les photos des employés sont **étiquetées avec leurs noms**.  
  - Un modèle peut **apprendre à associer une image à un employé spécifique**.  
  - Les **réseaux de neurones convolutionnels (CNN)** sont souvent utilisés pour la reconnaissance faciale.  

---

## **Cas 5 : Optimisation des feux de circulation urbains**  

- **Votre choix :** Apprentissage par renforcement (RL)  
- **Justification :**  
  - Le système doit **s’adapter en temps réel** aux conditions du trafic.  
  - Il apprend en **testant différentes stratégies** et en observant **leurs effets** sur la fluidité du trafic.  
  - Il maximise une récompense (ex. **réduction des embouteillages**).  
  - Approche basée sur **les méthodes RL comme Deep Q-Network (DQN)**.  

---

## **Cas 6 : Analyse d’images médicales**  

- **Votre choix :** Apprentissage non supervisé  
- **Justification :**  
  - L’hôpital **ne dispose pas d’annotations précises** sur les anomalies.  
  - L’objectif est de **repérer des structures inhabituelles** sans supervision.  
  - Les méthodes comme **l’algorithme des k-moyennes (K-Means) ou les autoencodeurs** sont souvent utilisées pour la détection d’anomalies dans les images médicales.  

---

## **Cas 7 : Recommandation dynamique sur plateforme vidéo**  

- **Votre choix :** Apprentissage par renforcement (RL)  
- **Justification :**  
  - Le système doit **ajuster en permanence** ses recommandations selon les actions des utilisateurs.  
  - Il apprend **en testant différentes suggestions** et en observant **les réactions des utilisateurs** (clics, temps de visionnage).  
  - RL permet d’optimiser **la satisfaction et l’engagement utilisateur** sur le long terme.  

---

## **Cas 8 : Classification automatique du spam**  

- **Votre choix :** Apprentissage supervisé  
- **Justification :**  
  - La base de données d’e-mails est **déjà étiquetée** (spam ou non-spam).  
  - L’objectif est de **classer** les nouveaux e-mails selon les modèles détectés dans les données passées.  
  - Les algorithmes de **Naïve Bayes**, **SVM**, ou **réseaux de neurones** sont souvent utilisés pour ce type de classification.  

---

## **Cas 9 : IA pour jeu vidéo stratégique en temps réel**  

- **Votre choix :** Apprentissage par renforcement (RL)  
- **Justification :**  
  - L’IA doit **prendre des décisions stratégiques successives** et s’adapter aux actions des adversaires humains.  
  - Elle doit **tester différentes stratégies**, apprendre de ses erreurs et ajuster son gameplay.  
  - **Deep Reinforcement Learning (DRL)** est utilisé dans des IA comme **AlphaStar de DeepMind** pour StarCraft II.  

---

## **Cas 10 : Classification automatique d’articles de presse**  

- **Votre choix :** Apprentissage non supervisé  
- **Justification :**  
  - Il n’y a **aucune catégorie prédéfinie** pour classer les articles.  
  - L’objectif est de **découvrir automatiquement** les différents sujets.  
  - Les **algorithmes de clustering** (ex. **K-Means**, **LDA** pour le regroupement de textes) sont bien adaptés.  

---

# **Synthèse des Réponses**  

| **Cas** | **Type d'Apprentissage** | **Pourquoi ?** |
|---------|--------------------------|----------------|
| Détection de fraudes bancaires | Supervisé | Historique de transactions étiquetées (fraude ou non-fraude). |
| Regroupement clients | Non supervisé | Pas d’étiquettes, objectif de segmentation client. |
| Navigation d’un robot | RL | Prise de décisions séquentielles, adaptation à l’environnement. |
| Reconnaissance faciale | Supervisé | Images étiquetées avec les noms des employés. |
| Feux de circulation intelligents | RL | Optimisation dynamique en fonction du trafic. |
| Analyse d’images médicales | Non supervisé | Détection d’anomalies sans indications préalables. |
| Recommandation sur plateforme vidéo | RL | Apprentissage basé sur les interactions en temps réel. |
| Classification du spam | Supervisé | Base de données annotée (spam ou non-spam). |
| IA pour jeux vidéo | RL | Prise de décisions stratégiques en temps réel. |
| Classification d’articles de presse | Non supervisé | Découverte automatique des sujets. |

---

# **Conclusion**  

- **L’apprentissage supervisé** est utilisé lorsque des **données étiquetées** sont disponibles pour l’entraînement.  
- **L’apprentissage non supervisé** est utilisé lorsque les données ne sont **pas annotées** et qu’on veut découvrir des structures cachées.  
- **L’apprentissage par renforcement (RL)** est utilisé lorsque les décisions influencent **l’état futur** et nécessitent une **optimisation sur le long terme**.  
