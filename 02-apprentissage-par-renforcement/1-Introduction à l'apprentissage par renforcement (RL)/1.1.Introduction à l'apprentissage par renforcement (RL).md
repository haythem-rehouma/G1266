# Introduction à l'apprentissage par renforcement (RL)  

## 1. Définition et objectifs  

L'apprentissage par renforcement (*Reinforcement Learning*, ou RL) est une branche de l'intelligence artificielle où un **agent** apprend à prendre des décisions optimales en interagissant avec un **environnement**.  

Contrairement à l’apprentissage supervisé, le RL ne fournit pas de solutions prédéfinies sous forme d’exemples étiquetés. L’agent doit **découvrir lui-même la meilleure stratégie** en explorant différentes actions et en recevant des récompenses ou des pénalités en retour.  

_La différence avec un apprentissage classique ? Plutôt que d'apprendre à partir de données existantes, l'agent apprend **par essais et erreurs**, comme un enfant qui apprend à marcher._  

### Objectif principal du RL  
L’agent cherche à maximiser la **somme des récompenses cumulées** sur le long terme, plutôt que de se focaliser uniquement sur des gains immédiats.  

_Un peu comme dans un jeu vidéo : un joueur ne se contente pas d’accumuler des points au premier niveau, il optimise sa stratégie pour gagner la partie entière._  

---

## 2. Mécanisme d’apprentissage  

Le RL repose sur un **cycle d’interactions** entre l’agent et l’environnement :  

1. **L’agent prend une action** en fonction de l’état actuel de l’environnement.  
2. **L’environnement réagit** et retourne une **récompense** ou une **pénalité**.  
3. **L’agent ajuste sa stratégie** pour améliorer ses futures décisions.  

_L'agent fonctionne comme un joueur de poker qui apprend en jouant plusieurs parties, en ajustant son jeu en fonction des victoires et des défaites._  

---

## 3. Principes fondamentaux  

### 3.1. Essai et erreur  
L'agent explore différentes actions et apprend **progressivement** lesquelles produisent les meilleurs résultats.  

_C’est comme apprendre à faire du vélo : au début, on tombe plusieurs fois, mais à force d’essayer, on comprend comment maintenir l’équilibre._  

### 3.2. Décisions séquentielles  
Chaque action influence l’état futur de l’environnement, et donc **les décisions suivantes**.  

_Imagine un jeu d'échecs : chaque coup que tu joues change le plateau, influençant les stratégies disponibles par la suite._  

### 3.3. Maximisation des récompenses cumulées  
L’agent ne cherche pas seulement à **gagner rapidement**, mais à **optimiser ses actions pour obtenir un maximum de récompenses sur la durée**.  

_Pour un investisseur, cela signifie ne pas chercher un profit immédiat, mais construire un portefeuille rentable à long terme._  

---

## 4. Illustration : un agent dans un labyrinthe  

Prenons un exemple concret : un agent qui doit trouver un diamant caché dans un labyrinthe.  

- Chaque **déplacement** est une **action**.  
- En fonction de sa position, il peut recevoir une **récompense** (se rapprocher du diamant) ou une **pénalité** (se perdre).  
- À force d’essais, il apprend à **trouver le chemin optimal**.  

_Pense à un robot aspirateur : il explore la maison, comprend où sont les obstacles et optimise ses trajets pour nettoyer plus efficacement._  

---

## 5. Synthèse  

- L’apprentissage par renforcement repose sur un agent qui explore son environnement en prenant des décisions et en recevant un feedback.  
- Contrairement à d'autres types d’apprentissage, le RL est basé sur l’interaction et l’amélioration continue par essais et erreurs.  
- Il est particulièrement utilisé pour résoudre des problèmes complexes où chaque action influence l’avenir, comme la robotique, les jeux ou la gestion de systèmes autonomes.  
