# GUIDE â€“ MLOps **Redâ€¯Wine Quality**

DockerÂ +Â MLflowÂ +Â PostgreSQLÂ +Â pgAdminÂ +Â PortainerÂ +Â **FastAPI**Â +Â **Streamlit**

> **Extension par rapport Ã  la version prÃ©cÃ©dente**â€¯:
> â€“ Ajout dâ€™une API REST (FastAPIâ€¯: portâ€¯8000)
> â€“ Ajout dâ€™un tableau de bord interactif (Streamlitâ€¯: portâ€¯8501)
> â€“ PossibilitÃ© de lancer â€“ depuis le navigateur â€“ des entraÃ®nements MLflow avec hyperâ€‘paramÃ¨tres choisis Ã  la volÃ©e, dâ€™observer les runs en temps rÃ©el et de servir les prÃ©dictions.


<br/>

# 0. TABLE DES PORTS

| Service    | Port conteneur | Port hÃ´te | Description courte         |
| ---------- | -------------- | --------- | -------------------------- |
| MLflow UI  | 5000           | 5000      | Suivi des expÃ©riences      |
| FastAPI    | 8000           | 8000      | API REST (train + predict) |
| Streamlit  | 8501           | 8501      | Dashboard interactif       |
| PostgreSQL | 5432           | 5432      | Base de donnÃ©es MLflow     |
| pgAdmin    | 80             | 8080      | GUI PostgreSQL             |
| Portainer  | 9000           | 9000      | Supervision conteneurs     |

Assurezâ€‘vous dâ€™ouvrir **5000,â€¯8000,â€¯8501,â€¯8080,â€¯9000** (TCP entrants) dans votre pareâ€‘feuâ€¯/â€¯NSG.



<br/>

# 1. FICHIERS Ã€ CRÃ‰ER / MODIFIER

```
mlops-redwine/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ train_model.py
â”œâ”€â”€ api_app.py           <-- FastAPI
â”œâ”€â”€ streamlit_app.py     <-- Streamlit
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ red-wine-quality.csv
â””â”€â”€ mlruns/
```



### 1.1 `requirements.txt` (complÃ©tÃ©)

```
pandas
numpy
scikit-learn
mlflow
psycopg2-binary
fastapi
uvicorn[standard]
streamlit
```



### 1.2 `Dockerfile` (un seul conteneur Â«Â mlflowÂ Â» sachant tout faire)

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . .

RUN apt-get update && apt-get install -y git \
 && pip install --upgrade pip \
 && pip install -r requirements.txt \
 && apt-get clean && rm -rf /var/lib/apt/lists/*

# EntrÃ©e par dÃ©fautÂ : shell
CMD ["bash"]
```



### 1.3 `train_model.py`

*(identique sauf sÃ©parateur `sep=';'`) â€“ dÃ©jÃ  prÃ©sentÃ©, donc inchangÃ©.*

---

### 1.4 `api_app.py` â€” **FastAPI**

```python
from fastapi import FastAPI
from pydantic import BaseModel
import subprocess, uuid, os

app = FastAPI(title="Redâ€‘Wine MLOps API")

class TrainRequest(BaseModel):
    model: str       # elasticnet | ridge | lasso
    alpha: float
    l1_ratio: float | None = None   # ignorÃ© hors ElasticNet

@app.post("/train")
def train(req: TrainRequest):
    """Lance un entraÃ®nement MLflow en sousâ€‘processus."""
    run_id = str(uuid.uuid4())[:8]
    cmd = [
        "python", "train_model.py",
        "--model", req.model,
        "--alpha", str(req.alpha)
    ]
    if req.model == "elasticnet":
        cmd += ["--l1_ratio", str(req.l1_ratio or 0.5)]
    # On passe la variable d'env pour que le sousâ€‘processus parle Ã  MLflow
    env = os.environ.copy()
    env["MLFLOW_TRACKING_URI"] = env.get("MLFLOW_TRACKING_URI", "http://mlflow:5000")
    subprocess.Popen(cmd, env=env)
    return {"status": "started", "run_id": run_id, "cmd": " ".join(cmd)}

class PredictRequest(BaseModel):
    alcohol: float
    volatile_acidity: float
    sulphates: float

@app.post("/predict")
def predict(inp: PredictRequest):
    """Exemple minimal de prÃ©diction â€˜Ã  la mainâ€™. 
       (On chargerait normalement un modÃ¨le MLflow.)"""
    # Formule naÃ¯ve pour dÃ©monstration
    score = 3 + 0.3*inp.alcohol - 1.2*inp.volatile_acidity + 0.8*inp.sulphates
    return {"quality_estimate": round(score, 2)}
```



### 1.5 `streamlit_app.py` â€” **Dashboard**

```python
import streamlit as st
import requests, json, pandas as pd

st.set_page_config(page_title="Redâ€‘Wine Trainer", layout="wide")

st.title("ðŸ· Redâ€‘Wine Trainer â€“ Interface Streamlit")
st.markdown(
    "Lancez des entraÃ®nements MLflow et observezâ€‘les en temps rÃ©el dans "
    "[MLflow UI](http://localhost:5000).")

with st.form("train_form"):
    model = st.selectbox("ModÃ¨le", ["elasticnet", "ridge", "lasso"])
    alpha = st.slider("alpha", 0.01, 2.0, 0.5, 0.01)
    l1_ratio = st.slider("l1_ratio (ElasticNet)", 0.0, 1.0, 0.5, 0.05)
    submitted = st.form_submit_button("ðŸš€ Lancer l'entraÃ®nement")
    if submitted:
        payload = {"model": model, "alpha": alpha, "l1_ratio": l1_ratio}
        resp = requests.post("http://api:8000/train",
                             data=json.dumps(payload),
                             headers={"Content-Type": "application/json"})
        if resp.ok:
            st.success(f"Run dÃ©marrÃ©Â : {resp.json()['run_id']}")
        else:
            st.error("Erreur lors de lâ€™appel API")

st.header("PrÃ©vision rapide (dÃ©monstration)")
col1, col2, col3 = st.columns(3)
with col1: alcohol   = st.number_input("Alcohol",  8.0, 15.0, 10.0, 0.1)
with col2: vola_acid = st.number_input("Volatile acidity", 0.1, 1.5, 0.5, 0.01)
with col3: sulphates = st.number_input("Sulphates", 0.3, 1.8, 0.8, 0.05)

if st.button("ðŸ”® PrÃ©dire qualitÃ "):
    payload = {"alcohol": alcohol,
               "volatile_acidity": vola_acid,
               "sulphates": sulphates}
    r = requests.post("http://api:8000/predict",
                      data=json.dumps(payload),
                      headers={"Content-Type": "application/json"})
    st.write(r.json())
```



### 1.6 `docker-compose.yml` (mis Ã  jour)

```yaml
version: "3.8"

services:
  # ---------- PostgreSQL ----------
  postgres:
    image: postgres:14
    restart: unless-stopped
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow_db
    ports: ["5432:5432"]
    volumes: [postgres_data:/var/lib/postgresql/data]

  # ---------- Backend MLflow + code commun ----------
  mlflow:
    build: .
    restart: unless-stopped
    depends_on: [postgres]
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
    command: >
      mlflow server
      --backend-store-uri postgresql://mlflow:mlflow@postgres:5432/mlflow_db
      --default-artifact-root /app/mlruns
      --host 0.0.0.0
    ports: ["5000:5000"]
    volumes:
      - ./mlruns:/app/mlruns
      - ./data:/app/data

  # ---------- FastAPI ----------
  api:
    build: .
    restart: unless-stopped
    depends_on: [mlflow]
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
    command: uvicorn api_app:app --host 0.0.0.0 --port 8000 --reload
    ports: ["8000:8000"]
    volumes:
      - ./data:/app/data          # accÃ¨s dataset

  # ---------- Streamlit ----------
  streamlit:
    build: .
    restart: unless-stopped
    depends_on: [api]
    environment:
      STREAMLIT_SERVER_PORT: 8501
      MLFLOW_TRACKING_URI: http://mlflow:5000
    command: streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0
    ports: ["8501:8501"]
    volumes:
      - ./data:/app/data

  # ---------- pgAdmin ----------
  pgadmin:
    image: dpage/pgadmin4
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports: ["8080:80"]
    volumes: [pgadmin_data:/var/lib/pgadmin]

  # ---------- Portainer ----------
  portainer:
    image: portainer/portainer-ce
    restart: unless-stopped
    command: -H unix:///var/run/docker.sock
    ports: ["9000:9000"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data

volumes:
  postgres_data:
  pgadmin_data:
  portainer_data:
```

<br/>

# 2. BUILD & LANCEMENT

```bash
sudo -s
git clone https://github.com/hrhouma/install-docker.git
cd install-docker
chmod +x install-docker.sh
./install-docker.sh           # installe Docker + compose plugin v2
apt install docker-compose
cd /home/azureuser/
git clone https://github.com/haythem-rehouma/projetsmlops-3.git
docker-compose pull
docker-compose build --no-cache mlflow
docker-compose up -d
docker ps --format "table {{.Names}}\t{{.Ports}}"
```

Vous devez voir **6Â services**â€¯: `postgres`, `mlflow`, `api`, `streamlit`, `pgadmin`, `portainer`.


<br/>

# 3. UTILISATION

| Ã‰tape | Action                                                                                                                                                                                                                                              |
| ----- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1     | Visitez **Streamlit**â€¯: `http://<IP_VM>:8501`.<br>Choisissez un modÃ¨le, rÃ©glez `alpha` et (pour ElasticNet) `l1_ratio`, cliquez **Lancer l'entraÃ®nement**.<br>Le run dÃ©marre et apparaÃ®t instantanÃ©ment dans **MLflow UI** (`http://<IP_VM>:5000`). |
| 2     | Testez lâ€™APIÂ RESTÂ :                                                                                                                                                                                                                                 |

*Depuis votre machine locale*â€¯:

```bash
curl -X POST http://<IP_VM>:8000/train \
  -H "Content-Type: application/json" \
  -d '{"model":"ridge","alpha":0.4}'
```

*PrÃ©diction rapide*â€¯:

```bash
curl -X POST http://<IP_VM>:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"alcohol":11.0,"volatile_acidity":0.6,"sulphates":0.75}'
```

Vous obtenez un JSON avec lâ€™estimation de qualitÃ©.

<br/>

# 4. POINTS Dâ€™AMÃ‰LIORATION

| IdÃ©e                         | Piste de miseâ€¯enâ€¯Å“uvre                                                                            |
| ---------------------------- | ------------------------------------------------------------------------------------------------- |
| Signature MLflow             | Utiliser `mlflow.models.signature.infer_signature` pour logger `input_example` et la `signature`. |
| Prediction via modÃ¨le MLflow | Charger le dernier modÃ¨le avec `mlflow.pyfunc.load_model` dans `api_app.py`.                      |
| Authentification API         | Ajouter `fastapi.security` + JWT ou clÃ© API simple.                                               |
| Monitoring                   | Activer Prometheus + Grafana via Portainer pour CPU/RAM.                                          |
| Tests unitaires              | Ajouter `pytest` + GitHubÂ Actions CI/CD (build + docker push).                                    |

<br/>

# Â 5. Notre stack MLOps est prÃªteâ€¯!

- PageÂ Streamlit conviviale, API REST pour scripts externes, suivi MLflow complet, baseÂ PostgreSQL, pgAdmin, Portainer â€” le tout en **unâ€¯seul `docker-compose up -d`**.
